from FPSim2 import FPSim2Engine
import numpy as np
import argparse
import duckdb
import pandas as pd
from pathlib import Path
from dataclasses import dataclass
from typing import Sequence
from utils import convert_hac_to_mw, convert_mw_to_hac


def parse_args():
    parser = argparse.ArgumentParser(description='Search similar SMILES')
    parser.add_argument('-db', '--db_name', type=str, help='the name of the FPSIM2 fingerprint database',  required=True)
    parser.add_argument('-mol','--molecular_database', type=str, help='The folder path for the database', required=True, default='Molecular_database')
    parser.add_argument('-q','--query_path', type=str, help='File for the query in .smi format', required=True)
    parser.add_argument('-k','--top_k', type=int, help='How many molecular to retrieve (it might return less because of the algorithm)', required=False, default=100)
    parser.add_argument('-t','--threshold', type=float, help='The similarity threshold, faster when higher but it might return less molecules than specified', required=False, default=0.7)
    parser.add_argument('-n','--num_workers', type=int, help='The number of workers for the FPSIM2 search', required=False, default=100)
    parser.add_argument('-i', '--index_file', type=str, help='The index file generated by deduplication',  required=True)
    parser.add_argument('-c', '--output_file', type=str, help='The csv file name for the query results',  required=False, default="query_results.csv")
    parser.add_argument('-o', '--on_disk', action='store_false', help='Whether to perform on disk operations',  required=False)
    parser.add_argument('-mw', '--mw_range', nargs="+", help="The MW upper and/or the lower limit whn searching SMILES", defalt=None, required=False)
    parser.add_argument('-hac', '--hac_limits', nargs="+", help="The HAC upper and/or lower limit when searching SMILES", defalt=None, required=False)
    args = parser.parse_args()
    return args.db_name, args.molecular_database, args.index_file, args.top_k, args.threshold, args.num_workers, args.output_file, args.query_path, args.on_disk, args.hac_limits, args.mw_range


@dataclass
class SimilaritySearch:
    """
    Search similar molecules based on Tanimoto
    
    Parameters
    -----------
    db_name: str
        The name of the FPSIM2 fingerprint database
    index_file: str
        The index file generated by deduplication which tells the size of each HAC
    database_path: str
        The folder path for the database
    mw_range: Iterable[float] | None = None
        The range of molecular weights to filter. The first number is the lower bound and the second is the upper bound
    hac_limits: Iterable[int] | None = None
        The range of HACs to filter. The first number is the lower bound and the second is the upper bound.
    
    Only one of mw_range or hac_limits can be specified
    """
    
    db_name:str
    index_file: str
    database_path: str
    mw_range: Sequence[float] | None = None
    hac_limits: Sequence[int] | None = None
    
    @property
    def upper(self) -> int | None:
        if self.hac_limits is not None and self.mw_range is not None:
            raise ValueError("Only one of mw_range or hac_limits can be specified")
        elif self.hac_limits is not None:
            return self.hac_limits[0]
        elif self.mw_range is not None:
            return convert_mw_to_hac(self.mw_range[0])
        else:
            return None
        
    @property
    def lower(self) -> int | None:
        if self.hac_limits is not None and len(self.hac_limits) == 2:
            return self.hac_limits[1]
        elif self.mw_range is not None and len(self.mw_range[1]) == 2:
            return convert_mw_to_hac(self.mw_range[1])
        else:
            return None
    
    def querying(
        self, 
        query: str | list[str], 
        top_k: int=100,
        threshold: float = 0.5,
        workers: int=4,
        on_disk: bool=True):
        
        fpe = FPSim2Engine(self.db_name)
        search = {}
        if isinstance(query, str):
            query = [query]
        for que in query:
            if on_disk:
                results = fpe.on_disk_top_k(query, k=top_k, threshold=threshold, metric='tanimoto', n_workers=workers) 
            else:
                results = fpe.top_k(query, k=top_k, threshold=threshold, metric='tanimoto', n_workers=workers)
            search[que] = results
            
        return search

    def _filter_hacs(self, hac: int):
        u, l = True, True
        if self.upper is not None:
            u =  hac <= self.upper
        if self.lower is not None:
            l = hac >= self.lower                            
        return all([u, l])
        

    def find_hac_by_index(self, search_results: dict[str, np.array]) -> dict[str, list[int]]:
        """
        Given the indices of the search results find in which HAC the molecule is found and reduce the scopre when
        retrieving the SMILES strings
        """
        with open(self.index_file, "r") as st:
            lines = {int(x.strip().split("#")[-1]): int(x.split("#")[0].strip("HAC")) for x in st.readlines()}
        index_dict = {}
        bounds = np.array(sorted(lines.keys()))
        for query, result in search_results.items():
            index = sorted([x[0] for x in result])
            i = np.unique(np.searchsorted(bounds, index, side="right"))
            hacs = [lines.get(x) for x in bounds[i]]
            index_dict[query] = hacs
        return index_dict

    def convert_hac_topath(self,
        hac_dict: dict[str, list[int]], 
        ) -> dict[str, list[str]]:
        """
        Convert hac to parquet paths for the duck db read_parquet
        """
        parquet_paths = {}
        for query, hacs in hac_dict.items():
            hacs = filter(self._filter_hacs, hacs)
            parquet_paths[query] = [f"{self.database_path}/HAC_{hac}/*.parquet" for hac in hacs]
        return parquet_paths

    def retrieve_smiles(self,
        duck_con,
        indices: list[int],
        parquet_path: list[str],
        ) -> pd.DataFrame:
        """ 
        Retrieve the SMILES from the databases and convert them into Dataframes
        """
        res = duck_con.execute(f"SELECT SMILES, db_id, num_ID FROM read_parquet($path) WHERE num_ID IN $indices)", {"path": parquet_path, "indices": indices}).df()
        return res

    def batch_retrieve(
        self,
        search_result: dict[str, list[tuple[int, float]]], 
        parquet_paths: dict[str, list[str]],
        ) -> dict[str, pd.DataFrame]:
        
        #extract the index from the FPSIM2 results and generate the combined path and indices
        """
        Batch retrieve SMILES and db_id from the database using the results of FPSIM2 search and the parquet file paths.

        Args:
            search_result (dict[str, list[tuple[int, float]]]): The result of FPSIM2 search, where the key is the query molecule and the value is the index of the retrieved molecules.
            parquet_paths (dict[str, list[str]]): A dictionary containing the parquet file paths, where the key is the query molecule and the value is the path to the parquet files.

        Returns:
            dict[str, pd.DataFrame]: A dictionary containing the retrieved SMILES and db_id, where the key is the query molecule and the value is a pandas DataFrame containing the retrieved results.
        """

        index_dict = {query: sorted([int(u[0]) for u in ind]) for query, ind in search_result.items()}
        parquet = set()
        index = set()
        for i in parquet_paths.values():
            parquet.update(i)
        for i in index_dict.values():
            index.update(i)
            
        result = {}
        # connect to database and search using the combined indices and parquet files   
        db_con = duckdb.connect()
        res = self.retrieve_smiles(db_con, sorted(index), list(parquet))
        for query, index in index_dict.items():
            result[query] = res[res["num_ID"].isin(index)]
        
        return result
    
    def run(self, query: str | list[str], 
        top_k: int=100,
        threshold: float = 0.5,
        num_workers: int=4,
        on_disk: bool=True):
        """
        A convenient function to run the similarity search
        """
        search_results = self.querying(query, top_k, threshold, num_workers, on_disk)
        hac_dict = self.find_hac_by_index( search_results)
        parquet_paths = self.convert_hac_topath(hac_dict)
        smiles = self.batch_retrieve(search_results, parquet_paths)
        return pd.concat(smiles)

def main():
    db_name, molecular_database, index_file, top_k, threshold, num_workers, output_file, query_path, on_disk,hac_limits, mw_range = parse_args()
   
    with open(query_path) as w:
        query = [x.strip() for x in w.readlines()]

    search = SimilaritySearch(db_name, index_file, molecular_database, mw_range, hac_limits)
    smiles = search.run(query, top_k, threshold, num_workers, on_disk)
    
    Path(output_file).parents.mkdir(parents=True, exist_ok=True)
    smiles.to_csv(output_file)
    
    
if __name__ == "__main__":
    # Run this if this file is executed from command line but not if is imported as API
    main()